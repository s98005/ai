from diffusers import StableDiffusionPipeline, UniPCMultistepScheduler
import torch
import gc
import gradio as gr
import random
import os
from dotenv import load_dotenv
from openai import OpenAI
import re

# è‡ªå‹•é¸æ“‡è£ç½®
device = "cuda" if torch.cuda.is_available() else "cpu"

# è®€å– API Key
load_dotenv()
api_key = os.getenv("GROQ_API_KEY")

client = OpenAI(
    base_url="https://api.groq.com/openai/v1",
    api_key=api_key
)

# æ¨¡å‹èˆ‡é¢¨æ ¼å®šç¾©
model_name = "digiplay/Sweet-mix_v2.2_flat"
style_prompts = {
    "æµ´è¡£": "Yukata",
    "è³½åšæœ‹å…‹": "cyberpunk",
    "è¡—é ­é¢¨": "street fashion",
    "å­¸ç”Ÿåˆ¶æœ": "school uniform",
}
style_choices = list(style_prompts.keys())

# è¼‰å…¥æ¨¡å‹
pipe = StableDiffusionPipeline.from_pretrained(
    model_name,
    torch_dtype=torch.float32,
    use_safetensors=True
).to(device)

pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)

# ç¿»è­¯ä¸­æ–‡ Prompt æˆè‹±æ–‡
def translate_prompt_to_english(chinese_prompt):
    response = client.chat.completions.create(
        model="llama3-70b-8192",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å¹«åŠ©åœ–åƒç”Ÿæˆæ¨¡å‹ç¿»è­¯æç¤ºè©çš„åŠ©æ‰‹ï¼Œè«‹å°‡ä¸­æ–‡ prompt è½‰æ›è‹±æ–‡"},
            {"role": "user", "content": chinese_prompt}
        ]
    )
    return response.choices[0].message.content.strip()

def is_english(text):
    return re.match(r'^[a-zA-Z0-9\s.,\-_:;!?()\'"]+$', text.strip()) is not None

# ç”Ÿæˆåœ–ç‰‡ä¸»å‡½æ•¸
def generate_images(prompt, use_enhance, enhance_text, use_negative, negative_text,
                    use_custom_seed, custom_seed, height, width, steps, num_images, selected_styles):

    height = int(height)
    width = int(width)

    if not is_english(prompt):
        prompt = translate_prompt_to_english(prompt)

    if height % 8 != 0 or width % 8 != 0:
        raise ValueError("é«˜åº¦å’Œå¯¬åº¦å¿…é ˆæ˜¯8çš„å€æ•¸ï¼")

    base_seed = int(custom_seed) if use_custom_seed else random.randint(0, 2**32 - 1)
    seeds = [base_seed + i for i in range(num_images)]

    final_prompt = prompt
    if use_enhance and enhance_text:
        final_prompt += ", " + enhance_text
    if selected_styles:
        style_texts = [style_prompts[s] for s in selected_styles if s in style_prompts]
        final_prompt = ", ".join(style_texts) + ", " + final_prompt

    final_negative = negative_text if use_negative else None

    gc.collect()
    torch.cuda.empty_cache()

    images = []
    for i in range(num_images):
        generator = torch.Generator(device=device).manual_seed(seeds[i])
        with torch.no_grad():
            result = pipe(
                prompt=final_prompt,
                negative_prompt=final_negative,
                height=height,
                width=width,
                num_inference_steps=steps,
                guidance_scale=7.5,
                generator=generator
            )
        images.append(result.images[0])

    return images, f"ä½¿ç”¨çš„ random seeds: {seeds}"

# é è¨­å€¼
default_enhance = "masterpiece, ultra high quality, intricate skin details, cinematic lighting"
default_negative = "bad anatomy, blurry, disfigured, poorly drawn hands, extra fingers, mutated hands, low quality, worst quality"

# Gradio UI
with gr.Blocks(css=".gradio-container {background-color: #FAFAFA; padding: 20px;}") as demo:
    gr.Markdown("# ğŸ¨ MajicMIX v6 äº’å‹•åœ–åƒç”Ÿæˆå™¨")

    with gr.Row():
        with gr.Column(scale=6):
            selected_styles = gr.CheckboxGroup(choices=style_choices, label="é¸æ“‡é¢¨æ ¼", type="value")
            prompt = gr.Textbox(label="Prompt", placeholder="è¼¸å…¥æç¤ºè©", lines=3)

            use_enhance = gr.Checkbox(label="åŠ å¼· Prompt", value=True)
            enhance_text = gr.Textbox(label="åŠ å¼·å…§å®¹", value=default_enhance)

            use_negative = gr.Checkbox(label="ä½¿ç”¨ Negative Prompt", value=True)
            negative_text = gr.Textbox(label="Negative Prompt å…§å®¹", value=default_negative)

            use_custom_seed = gr.Checkbox(label="è‡ªè¨‚ Random Seed", value=False)
            custom_seed = gr.Number(label="æŒ‡å®š seed", value=42)

            height = gr.Dropdown(["512", "768", "1024"], label="é«˜åº¦ Height", value="512")
            width = gr.Dropdown(["512", "768", "1024"], label="å¯¬åº¦ Width", value="512")

            steps = gr.Slider(10, 50, value=20, step=5, label="ç”Ÿæˆæ­¥æ•¸ (Steps)")
            num_images = gr.Slider(1, 4, step=1, value=1, label="ç”Ÿæˆå¼µæ•¸")

            generate_btn = gr.Button("ğŸš€ é–‹å§‹ç”Ÿæˆï¼")

        with gr.Column(scale=6):
            gallery = gr.Gallery(label="ç”Ÿæˆçµæœ", columns=2, object_fit="contain", height="auto")
            seed_info = gr.Label(label="ä½¿ç”¨çš„ Random Seeds")

    generate_btn.click(
        fn=generate_images,
        inputs=[prompt, use_enhance, enhance_text, use_negative, negative_text,
                use_custom_seed, custom_seed, height, width, steps, num_images, selected_styles],
        outputs=[gallery, seed_info]
    )

    demo.launch(server_port=int(os.getenv("PORT", 7860)), server_name="0.0.0.0", debug=True)
    print("Service started and listening on port", os.getenv("PORT", 7860))
